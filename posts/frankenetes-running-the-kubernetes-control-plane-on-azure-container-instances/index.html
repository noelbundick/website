<!doctype html><html lang=en-us><head><title>Frankenetes! Running the Kubernetes control plane on Azure Container Instances | Noel Bundick</title><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content="I&rsquo;ve been learning more about Kubernetes lately - both how to use it, and how it works. I recently took the time to run through Kelsey Hightower&rsquo;s Kubernetes the Hard Way, specifically, the Azure version by Ivan Fioravanti. In addition to learning a lot, it sparked some interesting ideas on my flight home&mldr;
My thought was that these are just apps, processes, binaries that run with flags - boring. Boring is good!"><meta name=generator content="Hugo 0.96.0"><meta name=ROBOTS content="NOINDEX, NOFOLLOW"><link rel=stylesheet href=/css/style.css><link rel=stylesheet href=/css/custom.css><link rel="shortcut icon" href=/images/favicon.ico type=image/x-icon></head><body><nav class=navigation><a href=/><span class=arrow>‚Üê</span>Home</a>
<a href=/posts>Archive</a>
<a href=/tags>Tags</a></nav><main class=main><section id=single><h1 class=title>Frankenetes! Running the Kubernetes control plane on Azure Container Instances</h1><div class=tip><time datetime="2018-01-21 23:02:43 +0000 UTC">Jan 21, 2018</time>
<span class=split>¬∑</span>
<span>1411 words</span>
<span class=split>¬∑</span>
<span>7 minute read</span></div><aside class=toc><details><summary>Table of Contents</summary><div><nav id=TableOfContents><ul><li><a href=#overview>Overview</a></li><li><a href=#prerequisites-azure>Prerequisites: Azure</a></li><li><a href=#etcd>etcd</a><ul><li><a href=#write-ahead-log>Write ahead log</a></li><li><a href=#dns>DNS</a></li></ul></li><li><a href=#apiserver>apiserver</a></li><li><a href=#controller-manager>Controller manager</a></li><li><a href=#scheduler>Scheduler</a></li><li><a href=#kubeconfig>kubeconfig</a></li><li><a href=#nodes>Nodes!</a></li><li><a href=#whats-next>What&rsquo;s next?</a><ul><li><a href=#tls>TLS</a></li><li><a href=#dns-1>DNS</a></li><li><a href=#virtual-kubelet>Virtual Kubelet</a></li></ul></li></ul></nav></div></details></aside><div class=content><p>I&rsquo;ve been learning more about Kubernetes lately - both how to use it, and how it works. I recently took the time to run through Kelsey Hightower&rsquo;s <a href=https://github.com/kelseyhightower/kubernetes-the-hard-way target=_blank rel=noopener>Kubernetes the Hard Way</a>, specifically, the <a href=https://github.com/ivanfioravanti/kubernetes-the-hard-way-on-azure target=_blank rel=noopener>Azure version</a> by Ivan Fioravanti. In addition to learning a lot, it sparked some interesting ideas on my flight home&mldr;</p><p>My thought was that these are just apps, processes, binaries that run with flags - boring. Boring is good! They all have prebuilt images that let you run them as containers. And hey&mldr; <a href=https://docs.microsoft.com/en-us/azure/container-instances/ target=_blank rel=noopener>Azure Container Instances</a> lets me run containers without VM&rsquo;s. All the hard work was done; I wanted to see if I could glue it together to create a &ldquo;virtual Kubernetes cluster&rdquo;&mldr;</p><p>But I also knew there were already plenty of <a href=https://github.com/Azure/acs-engine target=_blank rel=noopener>sane</a> <a href=https://docs.microsoft.com/en-us/azure/aks/ target=_blank rel=noopener>ways</a> to run a Kubernetes cluster on Azure. And this felt like I was cobbling together parts from all over&mldr; and that if anyone did this in production, it could turn into a monster! So I decided to give my monstrous creation a name.</p><p><p class=markdown-image><img src=/posts/frankenetes-running-the-kubernetes-control-plane-on-azure-container-instances/frankenstein.jpg alt="Boris Karloff as the Kubernetes, I mean Frankenstein monster"></p></p><blockquote><p>Yes, I know that&rsquo;s actually Frankenstein&rsquo;s monster. Don&rsquo;t worry, your nits have been recorded.</p></blockquote><p>Frankenetes! I&rsquo;ll walk you through what I did and some of the gotchas, so you can run your own virtual Kubernetes cluster on ACI</p><h2 id=overview>Overview <a href=#overview class=anchor>üîó</a></h2><p>The Kubernetes control plane consists of a few moving parts</p><ul><li><a href=https://coreos.com/etcd/ target=_blank rel=noopener>etcd</a>: the distributed key/value store that holds cluster data</li><li>apiserver: REST API that validates & controls all reads/writes to etcd</li><li>controller manager: runs the core control loops of Kubernetes</li><li>scheduler: updates pods in the apiserver & assigns them to nodes</li></ul><p>I figured once those were in place, I should be able to connect nodes to my cluster and schedule workloads.</p><blockquote><p>This is a total hack, so I didn&rsquo;t secure <strong>anything</strong>. I don&rsquo;t see a reason why you wouldn&rsquo;t be able to secure all of this with TLS - it just wasn&rsquo;t the initial goal.</p></blockquote><h2 id=prerequisites-azure>Prerequisites: Azure <a href=#prerequisites-azure class=anchor>üîó</a></h2><p>I set up a couple of things in Azure to get started. A resource group to hold everything, and a storage account for all of my persistent data. Right now, it&rsquo;s mainly etcd data, but in the future, I can also store certs, logs, and so on.</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#268bd2>AZURE_RESOURCE_GROUP</span><span style=color:#719e07>=</span>frankenetes
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#586e75># As of 2.0.25, you have to use &#39;export&#39; for it to automagically set your storage acct</span>
</span></span><span style=display:flex><span><span style=color:#586e75># https://github.com/Azure/azure-cli/issues/5358</span>
</span></span><span style=display:flex><span><span style=color:#b58900>export</span> <span style=color:#268bd2>AZURE_STORAGE_ACCOUNT</span><span style=color:#719e07>=</span>frankenetes
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>az group create -n <span style=color:#268bd2>$AZURE_RESOURCE_GROUP</span> -l eastus
</span></span><span style=display:flex><span>az storage account create -n <span style=color:#268bd2>$AZURE_STORAGE_ACCOUNT</span> -g <span style=color:#268bd2>$AZURE_RESOURCE_GROUP</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#268bd2>AZURE_STORAGE_KEY</span><span style=color:#719e07>=</span><span style=color:#719e07>$(</span>az storage account keys list -n <span style=color:#268bd2>$AZURE_STORAGE_ACCOUNT</span> -g <span style=color:#268bd2>$AZURE_RESOURCE_GROUP</span> --query <span style=color:#2aa198>&#39;[0].value&#39;</span> -o tsv<span style=color:#719e07>)</span>
</span></span></code></pre></div><p><p class=markdown-image><img src=/posts/frankenetes-running-the-kubernetes-control-plane-on-azure-container-instances/young_frankenstein.jpg alt="Maybe I should have named it Abby Normal"></p></p><h2 id=etcd>etcd <a href=#etcd class=anchor>üîó</a></h2><p>As the backing data store, etcd needed to come up first. Kubernetes the Hard Way had most of the flags I needed, and the help for <code>az container create</code> gave me everything I needed to map my <code>data-dir</code> to an Azure File share.</p><h3 id=write-ahead-log>Write ahead log <a href=#write-ahead-log class=anchor>üîó</a></h3><p>Unfortunately, I ran into some unusual issues on startup. My limited understanding is that etcd takes a lock on the write ahead log directory, then renames a temp file to boot up. This works fine inside the container, but when mapped to Azure Files, it can&rsquo;t perform the rename (due to the lock), fails, and then the container gets stuck in a crash loop. Setting the <code>wal-dir</code> path to something inside the container resolves the issue, but since the log no longer outlives the container, the data store can suffer data loss.</p><blockquote><p>This could likely be solved if ACI supported additional volume types, etcd was patched to work around the locking issue, etc. Like I said, this is a hack&mldr;</p></blockquote><h3 id=dns>DNS <a href=#dns class=anchor>üîó</a></h3><p>My next issue was the <code>advertise-client-urls</code>. ACI gave me a public IP from, but it was dynamically generated and I wasn&rsquo;t able to specify it or know it until <strong>after</strong> the container group had been created. I needed another level of abstraction - DNS to the rescue! I&rsquo;m listening on all addresses inside the container, and then I configured DNS to let the apiserver resolve my etcd host from outside the container.</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#586e75># Create an Azure File share to hold cluster data</span>
</span></span><span style=display:flex><span>az storage share create -n etcd
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#586e75>#WARNING! This isn&#39;t truly useful until I fix the write ahead log &amp; secure the cluster</span>
</span></span><span style=display:flex><span><span style=color:#586e75>#TODO: figure out why I get &#34;create wal error: rename /etcd/data/member/wal.tmp /etcd/data/member/wal: permission denied&#34; when --wal-dir is not set</span>
</span></span><span style=display:flex><span>az container create -g <span style=color:#268bd2>$AZURE_RESOURCE_GROUP</span> <span style=color:#cb4b16>\
</span></span></span><span style=display:flex><span><span style=color:#cb4b16></span>  --name etcd <span style=color:#cb4b16>\
</span></span></span><span style=display:flex><span><span style=color:#cb4b16></span>  --image quay.io/coreos/etcd:v3.2.8 <span style=color:#cb4b16>\
</span></span></span><span style=display:flex><span><span style=color:#cb4b16></span>  --azure-file-volume-account-name <span style=color:#268bd2>$AZURE_STORAGE_ACCOUNT</span> <span style=color:#cb4b16>\
</span></span></span><span style=display:flex><span><span style=color:#cb4b16></span>  --azure-file-volume-account-key <span style=color:#268bd2>$AZURE_STORAGE_KEY</span> <span style=color:#cb4b16>\
</span></span></span><span style=display:flex><span><span style=color:#cb4b16></span>  --azure-file-volume-share-name etcd <span style=color:#cb4b16>\
</span></span></span><span style=display:flex><span><span style=color:#cb4b16></span>  --azure-file-volume-mount-path /etcd <span style=color:#cb4b16>\
</span></span></span><span style=display:flex><span><span style=color:#cb4b16></span>  --ports <span style=color:#2aa198>2379</span> <span style=color:#2aa198>2389</span> <span style=color:#cb4b16>\
</span></span></span><span style=display:flex><span><span style=color:#cb4b16></span>  --ip-address public <span style=color:#cb4b16>\
</span></span></span><span style=display:flex><span><span style=color:#cb4b16></span>  --command-line <span style=color:#2aa198>&#39;/usr/local/bin/etcd --name=aci --data-dir=/etcd/data --wal-dir=/etcd-wal --listen-client-urls=http://0.0.0.0:2379 --advertise-client-urls=http://frankenetes-etcd.noelbundick.com:2379&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#586e75># Grab the ipAddress.ip property &amp; update the A record for &#39;frankenetes-etcd.noelbundick.com&#39;</span>
</span></span></code></pre></div><p>And here&rsquo;s where I updated my DNS on CloudFlare</p><p><p class=markdown-image><img src=/posts/frankenetes-running-the-kubernetes-control-plane-on-azure-container-instances/frankenetes-etcd-dns.png alt="Adding the etcd record in CloudFlare DNS"></p></p><p>Finally, I verified everything by running a few etcdctl commands against the remote <code>frankenetes-etcd.noelbundick.com:2379</code> host</p><h2 id=apiserver>apiserver <a href=#apiserver class=anchor>üîó</a></h2><p>Next up - the apiserver. I used the latest stable <a href=https://github.com/kubernetes/kubernetes/tree/master/cluster/images/hyperkube target=_blank rel=noopener>hyperkube</a> image to run the API server, and connected to etcd using the DNS name.</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#586e75># Create a share to hold logs/etc</span>
</span></span><span style=display:flex><span>az storage share create -n apiserver
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>az container create -g <span style=color:#268bd2>$AZURE_RESOURCE_GROUP</span> <span style=color:#cb4b16>\
</span></span></span><span style=display:flex><span><span style=color:#cb4b16></span>  --name apiserver <span style=color:#cb4b16>\
</span></span></span><span style=display:flex><span><span style=color:#cb4b16></span>  --image gcr.io/google-containers/hyperkube-amd64:v1.9.2 <span style=color:#cb4b16>\
</span></span></span><span style=display:flex><span><span style=color:#cb4b16></span>  --azure-file-volume-account-name <span style=color:#268bd2>$AZURE_STORAGE_ACCOUNT</span> <span style=color:#cb4b16>\
</span></span></span><span style=display:flex><span><span style=color:#cb4b16></span>  --azure-file-volume-account-key <span style=color:#268bd2>$AZURE_STORAGE_KEY</span> <span style=color:#cb4b16>\
</span></span></span><span style=display:flex><span><span style=color:#cb4b16></span>  --azure-file-volume-share-name apiserver <span style=color:#cb4b16>\
</span></span></span><span style=display:flex><span><span style=color:#cb4b16></span>  --azure-file-volume-mount-path /apiserverdata <span style=color:#cb4b16>\
</span></span></span><span style=display:flex><span><span style=color:#cb4b16></span>  --ports <span style=color:#2aa198>6445</span> <span style=color:#cb4b16>\
</span></span></span><span style=display:flex><span><span style=color:#cb4b16></span>  --ip-address public <span style=color:#cb4b16>\
</span></span></span><span style=display:flex><span><span style=color:#cb4b16></span>  --command-line <span style=color:#2aa198>&#39;/apiserver  --advertise-address=0.0.0.0 --allow-privileged=true --apiserver-count=1 --audit-log-maxage=30 --audit-log-maxbackup=3 --audit-log-maxsize=100 --audit-log-path=/apiserverdata/log/audit.log --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --etcd-servers=http://frankenetes-etcd.noelbundick.com:2379 --runtime-config=api/all --v=2 --runtime-config=admissionregistration.k8s.io/v1alpha1 --enable-swagger-ui=true --event-ttl=1h --service-node-port-range=30000-32767 --insecure-bind-address=0.0.0.0 --insecure-port 6445&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#586e75># Grab the ipAddress.ip property &amp; update the A record for &#39;frankenetes-apiserver.noelbundick.com&#39;</span>
</span></span></code></pre></div><blockquote><p>Running on 6445 instead of 6443 was me &ldquo;securing&rdquo; my cluster by not using a default port. Security through obscurity is dumb. Don&rsquo;t do what I did for anything that matters</p></blockquote><p>And one more DNS update for the apiserver</p><p><p class=markdown-image><img src=/posts/frankenetes-running-the-kubernetes-control-plane-on-azure-container-instances/frankenetes-apiserver-dns.png alt="Adding the apiserver record in CloudFlare DNS"></p></p><p>To verify, I hit the apiserver endpoint by running <code>curl http://frankenetes-apiserver.noelbundick.com:6445/version</code></p><h2 id=controller-manager>Controller manager <a href=#controller-manager class=anchor>üîó</a></h2><p>Cool! The hard part was done. Smooth sailing from here on out. The controller manager was pretty straightforward - I just pointed it at the apiserver. No certs, no problems!</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>az container create -g <span style=color:#268bd2>$AZURE_RESOURCE_GROUP</span> <span style=color:#cb4b16>\
</span></span></span><span style=display:flex><span><span style=color:#cb4b16></span>  --name controllermanager <span style=color:#cb4b16>\
</span></span></span><span style=display:flex><span><span style=color:#cb4b16></span>  --image gcr.io/google-containers/hyperkube-amd64:v1.9.2 <span style=color:#cb4b16>\
</span></span></span><span style=display:flex><span><span style=color:#cb4b16></span>  --command-line <span style=color:#2aa198>&#39;/controller-manager --address=0.0.0.0 --cluster-cidr=10.200.0.0/16 --cluster-name=kubernetes --leader-elect=true --master=http://frankenetes-apiserver.noelbundick.com:6445 --service-cluster-ip-range=10.32.0.0/24 --v=2&#39;</span>
</span></span></code></pre></div><h2 id=scheduler>Scheduler <a href=#scheduler class=anchor>üîó</a></h2><p>Same story for the scheduler - it just needs to know where the apiserver is. Around this point, I really started to appreciate how modular the Kubernetes core components were.</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>az container create -g <span style=color:#268bd2>$AZURE_RESOURCE_GROUP</span> <span style=color:#cb4b16>\
</span></span></span><span style=display:flex><span><span style=color:#cb4b16></span>  --name scheduler <span style=color:#cb4b16>\
</span></span></span><span style=display:flex><span><span style=color:#cb4b16></span>  --image gcr.io/google-containers/hyperkube-amd64:v1.9.2 <span style=color:#cb4b16>\
</span></span></span><span style=display:flex><span><span style=color:#cb4b16></span>  --command-line <span style=color:#2aa198>&#39;/scheduler --leader-elect=true --master=http://frankenetes-apiserver.noelbundick.com:6445 --v=2&#39;</span>
</span></span></code></pre></div><h2 id=kubeconfig>kubeconfig <a href=#kubeconfig class=anchor>üîó</a></h2><p>I needed a way to connect to my cobbled together Kubernetes cluster (still with no nodes). I used the following to set up my kubeconfig and verify everything was working.</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#586e75># Set up cluster/context info in a standalone file</span>
</span></span><span style=display:flex><span>kubectl config set-cluster frankenetes --server<span style=color:#719e07>=</span>http://frankenetes-apiserver.noelbundick.com:6445 --kubeconfig<span style=color:#719e07>=</span>frankenetes.kubeconfig
</span></span><span style=display:flex><span>kubectl config set-context default --cluster<span style=color:#719e07>=</span>frankenetes --kubeconfig<span style=color:#719e07>=</span>frankenetes.kubeconfig
</span></span><span style=display:flex><span>kubectl config use-context default --kubeconfig<span style=color:#719e07>=</span>frankenetes.kubeconfig
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#586e75># Use the kubeconfig &amp; cross your fingers!</span>
</span></span><span style=display:flex><span><span style=color:#b58900>export</span> <span style=color:#268bd2>KUBECONFIG</span><span style=color:#719e07>=</span>frankenetes.kubeconfig
</span></span><span style=display:flex><span>kubectl version
</span></span><span style=display:flex><span>kubectl api-versions
</span></span></code></pre></div><p><p class=markdown-image><img src=/posts/frankenetes-running-the-kubernetes-control-plane-on-azure-container-instances/young_frankenstein_2.jpg alt="Frankenetes is alive"></p></p><h2 id=nodes>Nodes! <a href=#nodes class=anchor>üîó</a></h2><p>I ran through the manual steps in Kubernetes the Hard Way on Azure to create a single node, stripping out all the TLS bits along the way, and substituting 1.9.2 for 1.8.0.</p><p>Relevant sections:</p><ul><li><a href=https://github.com/ivanfioravanti/kubernetes-the-hard-way-on-azure/blob/master/docs/03-compute-resources.md target=_blank rel=noopener>Compute resources</a> - Virtual Network, Firewall Rules, Kubernetes Workers</li><li><a href=https://github.com/ivanfioravanti/kubernetes-the-hard-way-on-azure/blob/master/docs/09-bootstrapping-kubernetes-workers.md target=_blank rel=noopener>Bootstrapping the Kubernetes Worker Nodes</a></li></ul><p>After all was said & done, I was able to run pods on my node, all being controlled by Frankenetes running in ACI!</p><p><p class=markdown-image><img src=/posts/frankenetes-running-the-kubernetes-control-plane-on-azure-container-instances/pods.jpg alt="Lots of work to make it useful, but it does work!"></p></p><h2 id=whats-next>What&rsquo;s next? <a href=#whats-next class=anchor>üîó</a></h2><p>Not sure! This was a learning project to understand more about how the Kubernetes control plane really worked. It doesn&rsquo;t seem mysterious anymore. I feel like I can make it do what I want now. Here are some of my ideas so far. If you&rsquo;ve got more, please <a href=https://twitter.com/acanthamoeba target=_blank rel=noopener>hit me up on Twitter</a>!</p><h3 id=tls>TLS <a href=#tls class=anchor>üîó</a></h3><p>This is horribly insecure. Wide open. I should be able to use the DNS names to generate proper certs and secure everything. And then, of course, automate it all away.</p><h3 id=dns-1>DNS <a href=#dns-1 class=anchor>üîó</a></h3><p>I want to automate all the DNS steps using <a href=https://docs.microsoft.com/en-us/azure/event-grid/ target=_blank rel=noopener>Azure Event Grid</a>. My plan is to create the container group with a tag containing my desired DNS name (needs a PR for azure-cli!) Then, I can subscribe to Azure Resource Manager events and fire off an Azure Function that will take care of updating my DNS records based on the tag and the IP address that was provisioned. Think of it as a kind of Frankenstein version of kube-dns!</p><h3 id=virtual-kubelet>Virtual Kubelet <a href=#virtual-kubelet class=anchor>üîó</a></h3><p>Why stop at a virtual master control plane when I could have virtual nodes! I want to wire up <a href=https://github.com/virtual-kubelet/virtual-kubelet target=_blank rel=noopener>virtual-kubelet</a>. If that works, I could interact with my virtual cluster with my familiar Kubernetes toolkit (kubectl, kubectx, kubens, etc), but then <strong>all</strong> of my workloads would run on ACI. Not sure that&rsquo;s a useful concept, but hey - I&rsquo;ll give it a try and see if anyone likes it!</p><p><p class=markdown-image><img src=/posts/frankenetes-running-the-kubernetes-control-plane-on-azure-container-instances/young_frankenstein_3.gif alt="Me, when I got everything up and running"></p></p></div><div class=tags><a href=/tags/azure>azure</a>
<a href=/tags/kubernetes>kubernetes</a>
<a href=/tags/aci>aci</a></div></section></main><section><ul class=post-list><li>2021-10-14
<a href=/gists/optimizing-rust-container-builds/>Optimizing Rust container builds<h2></h2></a></li><li>2021-09-19
<a href=/gists/wsl2-container-development-with-moby/>WSL2 container development with Moby<h2></h2></a></li><li>2019-12-17
<a href=/gists/rdp-from-wsl/>RDP from WSL<h2></h2></a></li><li>2019-06-28
<a href=/gists/how-to-use-docker-build-secrets/>How to use Docker build secrets<h2></h2></a></li><li>2019-06-12
<a href=/gists/consuming-packages-from-a-private-azure-pipelines-python-artifact-feed/>Consuming packages from a private Azure Pipelines Python artifact feed<h2></h2></a></li><li>2019-01-13
<a href=/gists/gists-as-a-content-management-system/>Gists as a content management system<h2></h2></a></li><li>2019-01-12
<a href=/gists/azure-function-w--user-assigned-identity/>Azure Function w/ User Assigned Identity<h2></h2></a></li><li>2018-12-15
<a href=/gists/secure-code-execution-via-arm-template-and-azure-container-instances/>Secure code execution via ARM template and Azure Container Instances<h2></h2></a></li><li>2018-12-10
<a href=/gists/azure-redis-cli/>azure-redis-cli<h2></h2></a></li><li>2018-12-10
<a href=/gists/resize-azure-cloud-shell-storage/>Resize Azure Cloud Shell storage<h2></h2></a></li></ul></section><footer id=footer><div id=social><a class=symbol href=https://www.github.com/noelbundick rel=me target=_blank><svg fill="#bbb" width="28" height="28" viewBox="0 0 72 72" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><title>Github</title><desc>Created with Sketch.</desc><defs/><g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="Social-Icons---Rounded-Black" transform="translate(-264.000000, -939.000000)"><g id="Github" transform="translate(264.000000, 939.000000)"><path d="M8 72H64c4.418278.0 8-3.581722 8-8V8c0-4.418278-3.581722-8-8-8H8c-4.418278 811624501e-24-8 3.581722-8 8V64c541083001e-24 4.418278 3.581722 8 8 8z" id="Rounded" fill="#bbb"/><path d="M35.9985 13C22.746 13 12 23.7870921 12 37.096644c0 10.6440272 6.876 19.6751861 16.4145 22.8617681C29.6145 60.1797862 30.0525 59.4358488 30.0525 58.7973276 30.0525 58.2250681 30.0315 56.7100863 30.0195 54.6996482c-6.6765 1.4562499-8.085-3.2302544-8.085-3.2302544-1.0905-2.7829884-2.664-3.5239139-2.664-3.5239139C17.091 46.4500754 19.4355 46.4801943 19.4355 46.4801943c2.4075.1701719 3.675 2.4833051 3.675 2.4833051 2.142 3.6820383 5.6175 2.6188404 6.9855 2.0014024C30.3135 49.4077535 30.9345 48.3460615 31.62 47.7436831 26.2905 47.1352808 20.688 45.0691228 20.688 35.8361671c0-2.6308879.9345-4.781379 2.4705-6.4665327C22.911 28.7597262 22.0875 26.3110578 23.3925 22.9934585c0 0 2.016-.6475568 6.6 2.4697516C31.908 24.9285993 33.96 24.6620468 36.0015 24.6515052 38.04 24.6620468 40.0935 24.9285993 42.0105 25.4632101c4.581-3.1173084 6.5925-2.4697516 6.5925-2.4697516C49.9125 26.3110578 49.089 28.7597262 48.8415 29.3696344 50.3805 31.0547881 51.309 33.2052792 51.309 35.8361671c0 9.2555448-5.6115 11.29309-10.9575 11.8894446.860999999999997.7439374 1.629 2.2137408 1.629 4.4621184C41.9805 55.4089489 41.9505 58.0067059 41.9505 58.7973276 41.9505 59.4418726 42.3825 60.1918338 43.6005 59.9554002 53.13 56.7627944 60 47.7376593 60 37.096644 60 23.7870921 49.254 13 35.9985 13" fill="#fff"/></g></g></g></svg></a><a class=symbol href=https://twitter.com/acanthamoeba rel=me target=_blank><svg fill="#bbb" width="28" height="28" id="Capa_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="438.536" height="438.536" viewBox="0 0 438.536 438.536" style="enable-background:new 0 0 438.536 438.536"><g><path d="M414.41 24.123C398.333 8.042 378.963.0 356.315.0H82.228C59.58.0 40.21 8.042 24.126 24.123 8.045 40.207.003 59.576.003 82.225v274.084c0 22.647 8.042 42.018 24.123 58.102 16.084 16.084 35.454 24.126 58.102 24.126h274.084c22.648.0 42.018-8.042 58.095-24.126 16.084-16.084 24.126-35.454 24.126-58.102V82.225C438.532 59.576 430.49 40.204 414.41 24.123zM335.471 168.735c.191 1.713.288 4.278.288 7.71.0 15.989-2.334 32.025-6.995 48.104-4.661 16.087-11.8 31.504-21.416 46.254-9.606 14.749-21.074 27.791-34.396 39.115-13.325 11.32-29.311 20.365-47.968 27.117-18.648 6.762-38.637 10.143-59.953 10.143-33.116.0-63.76-8.952-91.931-26.836 4.568.568 9.329.855 14.275.855 27.6.0 52.439-8.565 74.519-25.7-12.941-.185-24.506-4.179-34.688-11.991-10.185-7.803-17.273-17.699-21.271-29.691 4.947.76 8.658 1.137 11.132 1.137 4.187.0 9.042-.76 14.56-2.279-13.894-2.669-25.598-9.562-35.115-20.697-9.519-11.136-14.277-23.84-14.277-38.114v-.571c10.085 4.755 19.602 7.229 28.549 7.422-17.321-11.613-25.981-28.265-25.981-49.963.0-10.66 2.758-20.747 8.278-30.264 15.035 18.464 33.311 33.213 54.816 44.252 21.507 11.038 44.54 17.227 69.092 18.558-.95-3.616-1.427-8.186-1.427-13.704.0-16.562 5.853-30.692 17.56-42.399 11.703-11.706 25.837-17.561 42.394-17.561 17.515.0 32.079 6.283 43.688 18.846 13.134-2.474 25.892-7.33 38.26-14.56-4.757 14.652-13.613 25.788-26.55 33.402 12.368-1.716 23.88-4.95 34.537-9.708C357.458 149.793 347.462 160.166 335.471 168.735z"/></g></svg></a></div><div class=copyright>¬© Copyright
2022
<span class=split><svg fill="#bbb" width="15" height="15" id="heart-15" xmlns="http://www.w3.org/2000/svg" width="15" height="15" viewBox="0 0 15 15"><path d="M13.91 6.75c-1.17 2.25-4.3 5.31-6.07 6.94-.1903.1718-.4797.1718-.67.0C5.39 12.06 2.26 9 1.09 6.75-1.48 1.8 5-1.5 7.5 3.45 10-1.5 16.48 1.8 13.91 6.75z"/></svg></span>Noel Bundick</div></footer></body></html>