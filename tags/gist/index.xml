<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>gist on Noel Bundick</title><link>/tags/gist/</link><description>Recent content in gist on Noel Bundick</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 14 Oct 2021 00:00:00 +0000</lastBuildDate><atom:link href="/tags/gist/index.xml" rel="self" type="application/rss+xml"/><item><title>Optimizing Rust container builds</title><link>/gists/optimizing-rust-container-builds/</link><pubDate>Thu, 14 Oct 2021 00:00:00 +0000</pubDate><guid>/gists/optimizing-rust-container-builds/</guid><description>Optimizing Rust container builds ðŸ”—I&amp;rsquo;m a Rust newbie, and one of the things that I&amp;rsquo;ve found frustrating is that the default docker build experience is extremely slow. As it downloads crates, then dependencies, then finally my app - I often get distracted, start doing something else, then come back several minutes later and forget what I was doing
Recently, I had the idea to make it a little better by combining multistage builds with some of the amazing features from BuildKit.</description></item><item><title>WSL2 container development with Moby</title><link>/gists/wsl2-container-development-with-moby/</link><pubDate>Sun, 19 Sep 2021 00:00:00 +0000</pubDate><guid>/gists/wsl2-container-development-with-moby/</guid><description>WSL2 container development with Moby ðŸ”—Building, pulling, pushing, and running containers is something many developers do often without even thinking. Most of my development over the past couple of years has been exclusively in a Linux environment, specifically WSL2.
Even prior to the recent licensing changes to Docker Desktop, I found myself increasingly as an engineer whose workflow didn&amp;rsquo;t line up with my tools. I never used the GUI features. I never built Windows containers.</description></item><item><title>RDP from WSL</title><link>/gists/rdp-from-wsl/</link><pubDate>Tue, 17 Dec 2019 00:00:00 +0000</pubDate><guid>/gists/rdp-from-wsl/</guid><description>This was an experiment in WSL interop from way back in May 2018. My goal was to be able to type noel-pc123 from a bash terminal and immediately launch into an RDP session. Should still work!
msrdp-template.rdp ðŸ”— This file is used with mstsc.exe to launch a remote desktop session This file must be encoded as UTF-16 Replace the following values with your own: DOMAIN\user: the credentials you will use for your connection mygateway.</description></item><item><title>How to use Docker build secrets</title><link>/gists/how-to-use-docker-build-secrets/</link><pubDate>Fri, 28 Jun 2019 00:00:00 +0000</pubDate><guid>/gists/how-to-use-docker-build-secrets/</guid><description>How to use Docker build secrets ðŸ”—It&amp;rsquo;s common to need access to secret data to fully build an application from scratch. Commonly, builds pull sources or binaries from a private repository that requires authentication - private PyPI, npm, NuGet, etc. It&amp;rsquo;s also common to use a Dockerfile to perform application build and packaging when deploying apps as containers, to take advantage of an isolated environment. This presents a challenge, as we don&amp;rsquo;t want any secrets (files, environment variables, etc) to be captured in our image layers.</description></item><item><title>Consuming packages from a private Azure Pipelines Python artifact feed</title><link>/gists/consuming-packages-from-a-private-azure-pipelines-python-artifact-feed/</link><pubDate>Wed, 12 Jun 2019 00:00:00 +0000</pubDate><guid>/gists/consuming-packages-from-a-private-azure-pipelines-python-artifact-feed/</guid><description>Consuming Azure Pipelines Python artifact feeds in Docker ðŸ”—Recently, I was building out a set of Python packages and services and needed to find a way to pull down packages from an Azure Artifacts feed into a Docker image. It was straightforward to use the tasks to package an artifact, authenticate to the feed, and publish.
I had to do a bit more digging to piece together a flow I was comfortable with for building container images.</description></item><item><title>Gists as a content management system</title><link>/gists/gists-as-a-content-management-system/</link><pubDate>Sun, 13 Jan 2019 00:00:00 +0000</pubDate><guid>/gists/gists-as-a-content-management-system/</guid><description>GitHub Gists as a content management system ðŸ”—I often use GitHub Gists to jot down quick snippets to share. Lately, I&amp;rsquo;ve also tried to make sure an add a proper README (and a LICENSE!) - partially so that readers have some context on what they&amp;rsquo;re looking at, but also so I can remember what the heck I was doing when I wrote whatever code I&amp;rsquo;ve slung out there.
Gists are horrible for discoverability, and I always forget the neat things I&amp;rsquo;ve hacked together.</description></item><item><title>Azure Function w/ User Assigned Identity</title><link>/gists/azure-function-w--user-assigned-identity/</link><pubDate>Sat, 12 Jan 2019 00:00:00 +0000</pubDate><guid>/gists/azure-function-w--user-assigned-identity/</guid><description>Azure utility functions ðŸ”—What is this? ðŸ”—It&amp;rsquo;s an ARM template and an Azure Function App (https://github.com/noelbundick/azure-utilities) that I use as a base for doing interesting things in Azure. Ex: Start a VM from a Chrome bookmark, spin up Azure Container Instances as Azure DevOps build agents on-demand, etc. Cleanup resource groups on a timer trigger, etc.
It uses User Assigned Identity so I don&amp;rsquo;t have to juggle certs or Service Principal credentials</description></item><item><title>Secure code execution via ARM template and Azure Container Instances</title><link>/gists/secure-code-execution-via-arm-template-and-azure-container-instances/</link><pubDate>Sat, 15 Dec 2018 00:00:00 +0000</pubDate><guid>/gists/secure-code-execution-via-arm-template-and-azure-container-instances/</guid><description>Secure code execution via ARM template and Azure Container Instances ðŸ”—What is this? ðŸ”—It&amp;rsquo;s a template to execute authenticated az commands from an ARM template deployment, without storing or passing credentials of any kind
Why did you make it? ðŸ”—I was recently looking to move my blog from Azure Web Apps to a static site hosted on Azure Storage.
I wanted to have an ARM template so I can stand up other sites / use as a reference, etc.</description></item><item><title>azure-redis-cli</title><link>/gists/azure-redis-cli/</link><pubDate>Mon, 10 Dec 2018 00:00:00 +0000</pubDate><guid>/gists/azure-redis-cli/</guid><description>azure-redis-cli ðŸ”—redis-cli + stunnel for easy connectivity to Azure Cache for Redis
TLDR ðŸ”—docker run --rm -it acanthamoeba/azure-redis-cli &amp;lt;cache_name&amp;gt; &amp;lt;key&amp;gt; Detailed Usage ðŸ”—# Swap these vars as needed REDIS=noel RG=redis # Get key KEY=$(az redis list-keys -n $REDIS -g $RG --query &amp;#39;primaryKey&amp;#39; -o tsv) # Launch redis-cli docker run --rm -it acanthamoeba/azure-redis-cli $REDIS $KEY Extra credit ðŸ”—Add this to your .bashrc/.zshrc
function azure-redis-cli() { REDIS=$1 RG=$(az redis list --query &amp;#39;[?</description></item><item><title>Resize Azure Cloud Shell storage</title><link>/gists/resize-azure-cloud-shell-storage/</link><pubDate>Mon, 10 Dec 2018 00:00:00 +0000</pubDate><guid>/gists/resize-azure-cloud-shell-storage/</guid><description>Resize Azure Cloud Shell storage ðŸ”—I found myself wanting to resize the amount of storage I had allocated to Azure Cloud Shell, and I wanted to script this out in a repeatable way, as I use various test accounts. It&amp;rsquo;s pretty easy to go hunt down the storage account &amp;amp; set the quota, but this lets me run something once from inside the shell.azure.com itself and skip the lookups / trips to the portal</description></item><item><title>Azure Container Instances as SOCKS proxy</title><link>/gists/azure-container-instances-as-socks-proxy/</link><pubDate>Fri, 30 Nov 2018 00:00:00 +0000</pubDate><guid>/gists/azure-container-instances-as-socks-proxy/</guid><description>Azure Container Instances as SOCKS proxy ðŸ”—Sometimes it&amp;rsquo;s useful to originate traffic from a specific region - etc to test global load balancers, DNS, etc. A common way to do this is to SSH to some remote VPN service or VM, then forward your traffic through that remote endpoint.
You can also use this to watch Netflix outside of your current country while traveling abroad :P
Azure Container Instances are a quick &amp;amp; easy way to do this as well - launch the ssh daemon in a container, expose port 22, and start forwarding traffic!</description></item><item><title>Locust on Azure Container Instances</title><link>/gists/locust-on-azure-container-instances/</link><pubDate>Wed, 06 Jun 2018 00:00:00 +0000</pubDate><guid>/gists/locust-on-azure-container-instances/</guid><description>Running Distributed Locust on Azure Container Instances ðŸ”—Locust is an open source load testing tool that can be run inside a container
Below is how I got Locust up and running on Azure Container Instances
Note: I prefer head/workers, controller/nodes, etc, but I&amp;rsquo;ve used master/slave for clarity &amp;amp; consistency with the Locust docs in this doc
Design ðŸ”— Single master container 3x slave containers These communicate with the master over a public IP &amp;amp; DNS name Azure File share to upload locustfiles, which are accessed by containers Basics ðŸ”—Create a resource group &amp;amp; a storage account with a sample locustfile</description></item><item><title>Register w/ Cloudflare DNS</title><link>/gists/register-w--cloudflare-dns/</link><pubDate>Mon, 28 May 2018 00:00:00 +0000</pubDate><guid>/gists/register-w--cloudflare-dns/</guid><description>Dynamic DNS w/ Cloudflare + PowerShell + Windows Scheduled Tasks ðŸ”—Copy registerCloudflare.ps1 to C:\tools\registerCloudflare.ps1
Scheduled Task ðŸ”—Pick a Trigger that makes sense for you. Some examples:
At computer startup Every 6 hours When connecting to the network Use the following for Actions
Program/script: C:\Windows\System32\WindowsPowerShell\v1.0\powershell.exe -Command &amp;#34;&amp;amp; &amp;#39;C:\tools\registerCloudflare.ps1&amp;#39; -Email &amp;#39;user@example.com&amp;#39; -ApiKey &amp;#39;XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX&amp;#39; -Domain &amp;#39;example.com&amp;#39; -Name &amp;#39;myfriendlyname&amp;#39;&amp;#34;</description></item><item><title>aci-compose</title><link>/gists/aci-compose/</link><pubDate>Fri, 04 May 2018 00:00:00 +0000</pubDate><guid>/gists/aci-compose/</guid><description>aci-compose ðŸ”—I learned today that requestb.in had shut down. Their GitHub repo told me I could run it myself &amp;amp; gave me instructions for Heroku.
I thought it would be neat to be able to use a docker-compose file &amp;amp; deploy it to Azure Container Instances. This 20 minutes of hacking gave me something fun
# Create a resource group az group create -n requestbin -l eastus # Run aci-compose # Usage: aci-compose {compose_yaml_path} {resource_group_name} {dns_prefix} .</description></item><item><title>Frankenetes TLS</title><link>/gists/frankenetes-tls/</link><pubDate>Mon, 19 Mar 2018 00:00:00 +0000</pubDate><guid>/gists/frankenetes-tls/</guid><description>Frankenetes TLS overview ðŸ”— Define what certs I want in the tls directory
ca-config.json defines my Certificate Authority Individual -csr.json files represent individual certs / Kubernetes user accounts All certs are signed by the CA, which allows the k8s api server to trust their authenticity CN= corresponds to a k8s user O= corresponds to a k8s group. There can be multiple I use az storage file upload-batch to put my configuration &amp;amp; create-certs.</description></item></channel></rss>